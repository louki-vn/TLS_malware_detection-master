import json
import logging
import sys
from pathlib import Path
from datetime import datetime
from typing import Iterator
import pandas as pd

import asyncio
from fastapi import FastAPI
from fastapi.responses import HTMLResponse, StreamingResponse
from fastapi.requests import Request
from fastapi.templating import Jinja2Templates
from fastapi.staticfiles import StaticFiles

import time
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

logging.basicConfig(stream=sys.stdout, level=logging.INFO, format="%(asctime)s %(levelname)s %(message)s")
logger = logging.getLogger(__name__)

application = FastAPI()
application.mount("/static", StaticFiles(directory="./"), name="static")
templates = Jinja2Templates(directory="./")

file_status = 0

def GetFilePath():
    path = Path().absolute() 
    path = str(path)
    path = path.replace("\\", "/") +"/Data/"
    return path

class MyHandler(FileSystemEventHandler):
    def on_modified(self, event):
        print(f'event type: {event.event_type}  path : {event.src_path}')
        global file_status
        file_status = 1
        
def readCSV():
    df = pd.read_csv("./Data/history_sample.csv",
                     parse_dates=['time'])
    df['time'] = df['time'].dt.strftime('%Y-%m-%d %H:%M:%S')
    return df

@application.get("/", response_class=HTMLResponse)
async def index(request: Request) -> templates.TemplateResponse:
    return templates.TemplateResponse("index.html", {"request": request})

def watchfile():
    path = GetFilePath()
    event_handler = MyHandler()
    observer = Observer()
    observer.schedule(event_handler, path=path, recursive=False)
    observer.start()

    try:
        while True:
            time.sleep(1)
            if file_status == 1:
                observer.stop()
                return True
    except KeyboardInterrupt:
        observer.stop()
    observer.join()

async def generate_random_data(request: Request) -> Iterator[str]:
    client_ip = request.client.host
    logger.info("Client %s connected", client_ip)
    
    data = readCSV()
   
    while True:        
        # Tổng malware
        sum = data['malware_label'].sum()   
        json_sum = json.dumps(
            {
                'sum': int(sum),
                'timeG': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
        )
        yield f"data:{json_sum}\n\n"
        for i in range(data.shape[0]): 
            if data.at[i, 'malware_label'] == 1:                           
                json_data = json.dumps(
                    {
                        "time": data.at[i, 'time'],
                        "value": int(data.at[i, 'malware_label']),
                        "srcip": data.at[i, 'srcip'],
                        "srcport": int(data.at[i, 'srcport']),
                        "desip": data.at[i, 'desip'],
                        "desport": int(data.at[i, 'desport']),                 
                    }
                )
                yield f"data:{json_data}\n\n"
                await asyncio.sleep(0.1)
        
        # Nếu file có sự thay đổi, đọc lại file và load dữ liệu mới lên biểu đồ
        if watchfile() == True:
            data = readCSV()
           
        global file_status
        file_status = 0
               


@application.get("/chart-data")
async def chart_data(request: Request) -> StreamingResponse:
    response = StreamingResponse(generate_random_data(request), media_type="text/event-stream")
    response.headers["Cache-Control"] = "no-cache"
    response.headers["X-Accel-Buffering"] = "no"
    return response
